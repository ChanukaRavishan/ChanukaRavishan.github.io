<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Chanuka Algama</title>

    <meta name="author" content="Chanuka">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Chanuka Algama
                </p>
                <p>I'm a Researcher at <a href="https://lirneasia.net/">LIRNEasia</a>, a leading think tank active across Asia-Pacific region, where I work with the Data, Algorithms and Policy team.
                </p>
                <p>
                  I hold a BSc (Honours) in Computer Science from the University of Kelaniya. One of my work was recently recognized when I won 2nd place at the IEEE’s Standards for Secure and Trusted Learning Systems competition which held in Valencia, Spain.  
                </p>
                <p style="text-align:center">
                  <a href="mailto:chanukaravishan25@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/Minimal_Academic_resume.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=nCeQ21wAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://x.com/Chanuka_Rav">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/ChanukaRavishan">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/20221114_172250.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/20221114_172250.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in computer vision, deep learning, generative AI, and image processing. My research primarily focuses on interpreting aspects of the physical world—such as shape, motion, color, and light—from images, often through the use of radiance fields. Some papers are <span class="highlight">highlighted</span>.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


    <!-- 1st project-->

    <tr onmouseout="ever_stop()" onmouseover="ever_start()" bgcolor="#ffffd0">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='ever_image'>
					  <img src='images/sat11.png' width=100%>
					</div>
          <img src='images/OpenCV.png' width=100%>
        </div>
        <script type="text/javascript">
          function ever_start() {
            document.getElementById('ever_image').style.opacity = "1";
          }

          function ever_stop() {
            document.getElementById('ever_image').style.opacity = "0";
          }
          ever_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2410.09563">
			<span class="papertitle">Robust Optical Flow calculation: A higher order differential approach
</span>
        </a>
        <em>Under review at VISAPP</em>, 2025
        <p></p>
        <p>
          Primary Focus: Solutions for the challenge of optimal correspondence calculation under conditions of substantial nonlinear motion patterns and vulnerability of the flow constraint to rapid spatial transformations.
          <br>
          Secondary Focus: Solutions for intricacies that can amplify due to inaccurate approximations inherent in numerical differentiation techniques.
        </p>
      </td>
    </tr>

    <!-- 2nd project-->

    <tr onmouseout="ever_stop_2()" onmouseover="ever_start_2()" bgcolor="#ffffd0">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='ever_image_2'>
					  <img src='images/image (3).png' width=100%>
					</div>
          <img src='images/output.png' width=100%>
        </div>
        <script type="text/javascript">
          function ever_start_2() {
            document.getElementById('ever_image_2').style.opacity = "1";
          }

          function ever_stop_2() {
            document.getElementById('ever_image_2').style.opacity = "0";
          }
          ever_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://github.com/LIRNEasia/rs_cdr_sei">
			<span class="papertitle"> Informing Public Policy with Machine Learning: Mapping Poverty in Sri Lanka Using Mobile Call Detail Records and Remote Sensing Data
</span>
        </a>
        <br>
				<a href="https://scholar.google.com/citations?user=XU07nQwAAAAJ&hl=en">Kasun Amarasinghe</a>
        <a href="">Merl Chandana</a>
        <a href="">Viren Dias</a>
				<br>
        <em>Accepted AAAI 2025</em>, AI for Public Missions
        <p></p>
        <p>
          To combat poverty effectively, the project examined the potential of utilizing mobile call detail records and remote sensing data to gain fresh insights into poverty’s spatial distribution. It used spatial econometric models, including Spatial Error and Bayesian Geostatistical models, to capture spatial dependencies and identify patterns of poverty.
        </p>
      </td>
    </tr>

    <!-- 3rd project-->
    
    <tr onmouseout="ever_stop_3()" onmouseover="ever_start_3()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='ever_image_3'>
					  <img src='images/Screenshot 2025-01-12 at 22.16.21.png' width=100%>
					</div>
          <img src='images/Screenshot 2025-01-12 at 22.16.30.png' width=100%>
        </div>
        <script type="text/javascript">
          function ever_start_3() {
            document.getElementById('ever_image_3').style.opacity = "1";
          }

          function ever_stop_3() {
            document.getElementById('ever_image_3').style.opacity = "0";
          }
          ever_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://github.com/LIRNEasia/urban-rs-sl/tree/main">
			<span class="papertitle">Using Medium Resolution Satellite Imagery and Machine Learning to Redefine Urban Areas in Sri
        Lanka
</span>
        </a>
        <p></p>
        <p>
          This research introduced an end-to-end open-source pipeline to predict the Built-up (Bu) and Non-Built-up (NBU) areas using satellite band data. Finally, the project provides the code base for implementing the UN- Habitat definition What is a City, to understand the patterns, trends, and boundaries of urbanization.
        </p>
      </td>
    </tr>

    <!-- 4th project-->
    
    <tr onmouseout="ever_stop()" onmouseover="ever_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='ever_image'>
					  <img src='images/webapp.png' width=100%>
					</div>
          <img src='' width=100%>
        </div>
        <script type="text/javascript">
          function ever_start() {
            document.getElementById('ever_image').style.opacity = "1";
          }

          function ever_stop() {
            document.getElementById('ever_image').style.opacity = "0";
          }
          ever_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://github.com/ChanukaRavishan/MistralRAG-LlamaIndex">
			<span class="papertitle">Conversational RAG with Memory-Based Context Enhancement
</span>
        </a>
        <p></p>
        <p>
          Primary Focus: RAG(Retrieval augmented generation) faces limitations in capturing context and understanding complex queries as the proximity of text chunks in the embedding space does not guarantee a meaningful question-and-answer pair.
        </p>
      </td>
    </tr>

    <!-- 5th project-->
    
    <tr onmouseout="ever_stop_5()" onmouseover="ever_start_5()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='ever_image_5'>
					  <img src='images/Colombo_night_sky.jpg' width=100%>
					</div>
          <img src='images/output_image.png' width=100%>
        </div>
        <script type="text/javascript">
          function ever_start_5() {
            document.getElementById('ever_image_5').style.opacity = "1";
          }

          function ever_stop_5() {
            document.getElementById('ever_image_5').style.opacity = "0";
          }
          ever_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://github.com/ChanukaRavishan/VincentVanGogh_VGG-19">
			<span class="papertitle">When Deep Learning Meets Van Gough 
</span>
        </a>
        <p></p>
        <p>
          This works by using a deep neural network to take two images—a content image and a feature image—and blend them together so that the output image looks like the content image but "painted" in the style of the style image. VGG-19, a 19-layer CNN trained on the ImageNet dataset, is utilized here. Since this implementation doesn't require training or fully connected layers, the trainable parameters are set to False.

To obtain a multi-level representation of the style image, feature correlations are calculated between different feature maps. The content loss between the content image and the output image is computed using the mean squared error (MSE) of localized shapes. However, for the style image, calculating loss through MSE is less effective, as the goal is to mimic the color and texture in the output image. Therefore, the Gram matrix is used to capture a more general representation of the style image.
        </p>
      </td>
    </tr>


          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Under construction
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
